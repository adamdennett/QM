---
title: "Prof D's Regression Sessions - Vol 3"
subtitle: "In the mix - the linear mix(ed effects model lecture)"
author: 
  - name: "Adam Dennett"
email: "a.dennett@ucl.ac.uk"
date-as-string: "1st August 2024"
other: "CASA0007 Quantitative Methods"
from: markdown+emoji
format:
  revealjs: 
    logo: "L6_images/CASA_logo.svg"
    template-partials: 
      - title-slide.html
    transition: none
    slide-number: TRUE
    preview-links: auto
    theme: casa-slides
    chalkboard: true
    
filters:
 - code-visibility
lightbox: auto
title-slide-attributes:
    data-background-image: "L6_images/regression.png"
    data-background-size: stretch
    data-background-opacity: "0.08"
    data-background-color: "#4e3c56"
---

```{r}
#| message: false
#| warning: false
#| include: false
library(casaviz)
library(tidyverse)
library(sf)
library(plotly)
library(leaflet)
library(rgl)
library(dplyr)
library(here)
library(stringr)
library(dplyr)
library(purrr)
library(janitor)
library(readxl)
library(tibble)
library(ggrepel)
library(gganimate)
library(interactions)
library(jtools)
#all england schools
edubase_schools <- read_csv("https://www.dropbox.com/scl/fi/fhzafgt27v30lmmuo084y/edubasealldata20241003.csv?rlkey=uorw43s44hnw5k9js3z0ksuuq&raw=1") %>% 
  clean_names() %>% 
  filter(phase_of_education_name == "Secondary") %>% 
  filter(establishment_status_name == "Open") %>% 
  mutate(urn = as.character(urn))

#read in Brighton Secondary Schools Data
brighton_sec_schools <- read_csv("https://www.dropbox.com/scl/fi/fhzafgt27v30lmmuo084y/edubasealldata20241003.csv?rlkey=uorw43s44hnw5k9js3z0ksuuq&raw=1") %>% 
  clean_names() %>% 
  filter(la_name == "Brighton and Hove") %>% 
  filter(phase_of_education_name == "Secondary") %>% 
  filter(establishment_status_name == "Open") %>%
  st_as_sf(., coords = c("easting", "northing")) %>% 
  st_set_crs(27700)

btn_urn_list <- brighton_sec_schools %>% 
  select(urn) 

england_abs <- read_csv(here("sessions","L6_data", "Performancetables_130242", "2022-2023", "england_abs.csv"), na = c("", "NA", "SUPP", "NP", "NE"))
england_census <- read_csv(here("sessions","L6_data", "Performancetables_130242", "2022-2023", "england_census.csv"), na = c("", "NA", "SUPP", "NP", "NE"))
england_ks4final <- read_csv(here("sessions","L6_data", "Performancetables_130242", "2022-2023", "england_ks4final.csv"), na = c("", "NA", "SUPP", "NP", "NE"))
england_school_information <- read_csv(here("sessions","L6_data", "Performancetables_130242", "2022-2023", "england_school_information.csv"), na = c("", "NA", "SUPP", "NP", "NE"))

la_codes <- read_csv(here("sessions","L6_data", "Performancetables_130249", "2022-2023", "la_and_region_codes_meta.csv"), na = c("", "NA", "SUPP", "NP", "NE")) %>% 
  clean_names()

england_ks4final <- england_ks4final %>%
  mutate(URN = as.character(URN)) %>%
  mutate(across(TOTPUPS:PTOTENT_E_COVID_IMPACTED_PTQ_EE, ~ parse_number(as.character(.))))

england_ks4final <- england_ks4final %>%
  filter(!is.na(URN))

england_abs <- england_abs %>%
  mutate(URN = as.character(URN))

england_census <- england_census %>%
  mutate(URN = as.character(URN))

england_school_information <- england_school_information %>%
  mutate(URN = as.character(URN))

# Left join england_ks4final with england_abs
england_school_2022_23 <- england_ks4final %>%
  left_join(england_abs, by = "URN") %>%
  left_join(england_census, by = "URN") %>%
  left_join(england_school_information, by = "URN")

data_types <- sapply(england_school_2022_23, class)
england_school_2022_23_meta <- data.frame(Field = names(data_types), DataType = data_types)

btn_sub <- england_school_2022_23 %>%
  filter(URN %in% btn_urn_list$urn)

#P8_BANDING
england_school_2022_23_not_special <- england_school_2022_23 %>%
  filter(MINORGROUP != "Special school" & ADMPOL.x == "NSE")

eng_sch_2022_23_not_special_plus <- england_school_2022_23_not_special %>% left_join(
  edubase_schools, by = join_by(URN == urn)
)


calculate_index_of_dissimilarity <- function(df, col_A, col_B) {
  # Ensure the dataframe has the necessary columns
  required_columns <- c(col_A, col_B)
  if (!all(required_columns %in% colnames(df))) {
    stop(paste("Dataframe must contain the columns:", paste(required_columns, collapse = ", ")))
  }
  
  # Calculate the total number of disadvantaged and non-disadvantaged pupils
  total_A <- sum(df[[col_A]], na.rm = TRUE)
  total_B <- sum(df[[col_B]], na.rm = TRUE)
  
  # Calculate the index of dissimilarity
  df$dissimilarity_component <- abs(df[[col_A]] / total_A - df[[col_B]] / total_B)
  index_of_dissimilarity <- 0.5 * sum(df$dissimilarity_component, na.rm = TRUE)
  
  return(index_of_dissimilarity)
}

calculate_gorard_segregation <- function(df, col_A, col_T) {
  # Ensure the dataframe has the necessary columns
  required_columns <- c(col_A, col_T)
  if (!all(required_columns %in% colnames(df))) {
    stop(paste("Dataframe must contain the columns:", paste(required_columns, collapse = ", ")))
  }
  
  # Calculate the total number of disadvantaged pupils and total pupils
  total_A <- sum(df[[col_A]], na.rm = TRUE)
  total_T <- sum(df[[col_T]], na.rm = TRUE)
  
  # Calculate the Gorard Segregation Index
  df$gorard_component <- abs(df[[col_A]] / total_A - df[[col_T]] / total_T)
  gorard_segregation <- 0.5 * sum(df$gorard_component, na.rm = TRUE)
  
  return(gorard_segregation)
}


# Apply the functions to each LEA and create a new dataframe with the results
results_df <- england_school_2022_23_not_special %>%
  group_by(LEA) %>%
  group_map(~ tibble(
    LEA = .y$LEA,
    index_of_dissimilarity = calculate_index_of_dissimilarity(.x, col_A = "TFSM6CLA1A", col_B = "TNOTFSM6CLA1A"),
    gorard_segregation = calculate_gorard_segregation(.x, col_A = "TFSM6CLA1A", col_T = "TPUP")
  )) %>%
  bind_rows()



```

```{r}
#| eval: false
#| include: false
library(plotly)

# Assuming merged_df has columns:
# index_of_dissimilarity, gorard_segregation, la_name, region_name

fig <- plot_ly(
  data = merged_df,
  x = ~index_of_dissimilarity,
  y = ~gorard_segregation,
  type = 'scatter',
  mode = 'markers',
  color = ~region_name,       # Color by region
  text = ~la_name,            # Hover shows Local Authority name
  hoverinfo = 'text+x+y',
  marker = list(size = 6, opacity = 0.7)
) %>%
  layout(
    title = "Scatter Plot of Index of Dissimilarity vs Gorard Segregation, all LEAs in England",
    xaxis = list(title = "Index of Dissimilarity"),
    yaxis = list(title = "Gorard Segregation Index")
  )

fig
```

```{r}
#| message: false
#| warning: false

base_path <- here("sessions", "L6_data", "Performancetables_130242", "2022-2023")
na_all <- c("", "NA", "SUPP", "NP", "NE", "SP", "SN", "LOWCOV", "NEW", "SUPPMAT")

england_filtered <- read_csv(file.path(base_path, "england_filtered.csv"), na = na_all) |> mutate(URN = as.character(URN))

#str(england_filtered)

england_filtered_clean <- england_filtered[
  !is.na(england_filtered$ATT8SCR) & 
  !is.na(england_filtered$PTFSM6CLA1A) &
  england_filtered$ATT8SCR > 0 &
  england_filtered$PTFSM6CLA1A > 0, 
]

```

# This week

## Recap

-   Last week we saw how multiple regression models can allow us to understand complex relationships between predictor and outcome variables
-   We began to explore how by increasing the complexity of our regression models, we can begin to observe how the effects of different variables can confound (obscrure) and mediate (partially cause) the effects of others, giving us a deeper understanding of our system of interest
-   We were able to see that with just a relatively small number of variables, we could explain most of the variation in school-level attainment scores in England

## OLS regression with interaction terms

```{r}
#| message: false
#| warning: false
#| width: 80%
# Fit linear model and get predicted values
model_data <- england_filtered %>%
  filter(!is.na(ATT8SCR), !is.na(PTFSM6CLA1A), !is.na(PERCTOT))

model_data <- model_data %>%
  filter(
    is.finite(ATT8SCR), ATT8SCR > 0,
    is.finite(PTFSM6CLA1A), PTFSM6CLA1A > 0,
    is.finite(PERCTOT), PERCTOT > 0
  )

lm_fit1 <- lm(log(ATT8SCR) ~ log(PTFSM6CLA1A) + log(PERCTOT), data = model_data, na.action = na.exclude)

#summary(lm_fit1)

model_data <- model_data %>%
  mutate(
    fitted_ATT8SCR = exp(fitted(lm_fit1)),
    resids_real = ATT8SCR - fitted_ATT8SCR
  )

model_data$gor_name <- relevel(factor(model_data$gor_name), ref = "South East")
model_data$log_PERCTOT <- log(model_data$PERCTOT)
model_data$log_PTFSM6CLA1A <- log(model_data$PTFSM6CLA1A)

#lm_fit3a <- lm(log(ATT8SCR) ~ log_PTFSM6CLA1A + log_PERCTOT * gor_name, data = model_data)
lm_fit3a <- lm(log(ATT8SCR) ~ log_PERCTOT * gor_name, data = model_data)

#plot_summs(lm_fit3a, robust = TRUE)

casa_palette <- as.character(casa_colours[1:9])

#scale_colour_casa()
# or another palette like casa_dark

interactions::interact_plot(
  lm_fit3a,
  pred = "log_PERCTOT",
  modx = "gor_name",
  plot.points = F,
  facet.modx = F,
  colors = casa_palette
)

england_model1 <- lm(log(ATT8SCR) ~ log(PTFSM6CLA1A), data = england_filtered_clean)

```

-   In our most sophisticated model we could even see how the relationship between our main predictor and our outcome might vary between levels of a categorical variable

## OLS regression with Interaction Terms

-   Interacting categorical variables with other continuous predictor variables allowed us to see how levels of continuous predictor slope coefficient vary according to the categorical predictor
-   In our example, we saw how in a simple bivariate model of Attainment 8 vs Disadvantage, the slope less severe in regions such as London, the West Midlands and Yorkshire and the Humber when compared to the South East.
-   The effects of concentrations of disadvantaged pupils in schools felt more severely in the South East.

## Drawbacks of OLS with Interaction

-   OLS assumes all observations (schools) are independent of each other, when in reality, they may have characteristics which mean they are not independent - i.e. they are in the same local authority or have similar Ofsted ratings which mean they share some characteristics with each other in terms of governance etc.
-   OLS assumes the effects (parameters) are constant (fixed) across the whole population / dataset
-   OLS assumes the errors are independent
-   OLS only has one global intercept with group level differences in the data only crudely represented with dummy variables

## Different Slopes and Intercepts - Attainment 8

```{r}
filtered_data <- england_filtered_clean %>%
  filter(OFSTEDRATING != "Inadequate" & !is.na(OFSTEDRATING))
filtered_region <- england_filtered_clean %>%
  filter(OFSTEDRATING != "Inadequate" & !is.na(OFSTEDRATING) & !is.na(gor_name))
btn_sub <- filtered_region %>%
  filter(URN %in% btn_urn_list$urn)

# Base plot with england_school_2022_23
plot <- ggplot(filtered_data, aes(y = log(ATT8SCR), x = log(PTFSM6CLA1A), colour = OFSTEDRATING)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear model line for england_school_2022_23
  labs(title = "Attainment 8 vs % Deprived Students, 2022-23",
       x = "log(% Deprived Students)",
       y = "log(Attainment 8 Score)",
       color = "Ofsted Rating") +
  theme_minimal()

# Add another layer with btn_sub points and labels with sticks
plot #+ 
#  geom_point(data = btn_sub, aes(y = log(ATT8SCR), x = log(PTFSM6CLA1A)), color = "black") +
#  geom_smooth(data = btn_sub, aes(y = log(ATT8SCR), x = log(PTFSM6CLA1A)), method = "lm", se = FALSE, color = "black") +  # Add linear model line for btn_sub
#  geom_text_repel(data = btn_sub, aes(y = log(ATT8SCR), x = log(PTFSM6CLA1A), label = SCHNAME.x), color = "black", size = 3, nudge_y = c(-1.5, 1.5), force = 10, box.padding = 0.5, max.overlaps = 10, direction = "both") 
```

## Different Slopes and Intercepts - Attainment 8

```{r}
library(ggplot2)
library(dplyr)

# Step 1: Compute lm coefficients per Ofsted rating
lm_labels <- england_filtered_clean %>%
  group_by(OFSTEDRATING) %>%
  summarise(
    model = list(lm(log(ATT8SCR) ~ log(PTFSM6CLA1A))),
    .groups = "drop"
  ) %>%
  mutate(
    intercept = sapply(model, function(m) coef(m)[1]),
    slope = sapply(model, function(m) coef(m)[2]),
    label = paste0("y = ", round(slope, 2), "x + ", round(intercept, 2))
  )

# Step 2: Merge label positions (optional: use median values for placement)
label_positions <- england_filtered_clean %>%
  group_by(OFSTEDRATING) %>%
  summarise(
    x = 0,
    y = 3.2,
    .groups = "drop"
  )

lm_labels <- left_join(lm_labels, label_positions, by = "OFSTEDRATING")

# Step 3: Plot with annotations
ggplot(england_filtered_clean, aes(y = log(ATT8SCR), x = log(PTFSM6CLA1A), colour = OFSTEDRATING)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_text(data = lm_labels, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) +
  labs(
    title = "Attainment 8 vs % Deprived Students, 2022-23",
    x = "log(% Deprived Students)",
    y = "log(Attainment 8 Score)",
    color = "Ofsted Rating"
  ) +
  theme_minimal() +
  facet_wrap(~ OFSTEDRATING)
```

```{r}
#| eval: false
#| include: false
filtered_data <- england_filtered_clean %>%
  filter(OFSTEDRATING != "Inadequate" & !is.na(OFSTEDRATING))
filtered_region <- england_filtered_clean %>%
  filter(OFSTEDRATING != "Inadequate" & !is.na(OFSTEDRATING) & !is.na(gor_name))
btn_sub <- filtered_region %>%
  filter(URN %in% btn_urn_list$urn)

# Base plot with england_school_2022_23
plot <- ggplot(filtered_data, aes(y = log(ATT8SCR), x = log(PERCTOT), colour = OFSTEDRATING)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear model line for england_school_2022_23
  labs(title = "Attainment 8 vs Overall Absence %, 2022-23",
       x = "% Overall Absence",
       y = "Attainment 8 Score",
       color = "Ofsted Rating") +
  theme_minimal()

# Add another layer with btn_sub points and labels with sticks
plot + 
  geom_point(data = btn_sub, aes(y = log(ATT8SCR), x = log(PERCTOT)), color = "black") +
  geom_smooth(data = btn_sub, aes(y = log(ATT8SCR), x = log(PERCTOT)), method = "lm", se = FALSE, color = "black") +  # Add linear model line for btn_sub
  geom_text_repel(data = btn_sub, aes(y = log(ATT8SCR), x = log(PERCTOT), label = SCHNAME.x), color = "black", size = 3, nudge_y = c(-1.5, 1.5), force = 10, box.padding = 0.5, max.overlaps = 10, direction = "both") 
```

```{r}
#| eval: false
#| include: false
ggplot(england_filtered_clean, aes(y = log(ATT8SCR), x = log(PERCTOT), colour = OFSTEDRATING)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear model line for england_school_2022_23
  labs(title = "Attainment 8 vs Overall Absence %, 2022-23",
       x = "% Overall Absence",
       y = "Attainment 8 Score",
       color = "Ofsted Rating") +
  theme_minimal() +
  facet_wrap(~ OFSTEDRATING)  # Facet plots for each Ofsted rating
```

## Different Slopes and Intercepts - Progress 8

```{r}

# Base plot with england_school_2022_23
library(ggplot2)

# Fit global linear model
global_model <- lm(P8MEA ~ PTFSM6CLA1A, data = filtered_data)
intercept <- round(coef(global_model)[1], 3)
slope <- round(coef(global_model)[2], 3)

# Create annotation text
annotation_text <- paste0("Global LM: y = ", intercept, " + ", slope, "x")

# Plot with individual colored lines and global black line
plot <- ggplot(filtered_data, aes(x = PTFSM6CLA1A, y = P8MEA, colour = OFSTEDRATING)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +  # Individual lines by OFSTEDRATING
  geom_smooth(method = "lm", se = FALSE, color = "black", aes(group = 1)) +  # Global line
  annotate("text", x = 10, 
           y = 2,
           label = annotation_text, hjust = 0, size = 4, color = "black") +
  labs(
    title = "Progress 8 vs % Deprived Students, 2022-23",
    x = "% Deprived Students",
    y = "Progress 8 Score",
    color = "Ofsted Rating"
  ) +
  theme_minimal()

# Add another layer with btn_sub points and labels with sticks
plot #+ 
#  geom_point(data = btn_sub, aes(y = P8MEA, x = PTFSM6CLA1A), color = "black") +
#  geom_smooth(data = btn_sub, aes(y = P8MEA, x = PTFSM6CLA1A), method = "lm", se = FALSE, color = "black") +  # Add linear model line for btn_sub
#  geom_text_repel(data = btn_sub, aes(y = P8MEA, x = PTFSM6CLA1A, label = SCHNAME.x), color = "black", size = 3, nudge_y = c(-1.5, 1.5), force = 10, box.padding = 0.5, max.overlaps = 10, direction = "both") 
```

## Different Slopes and Intercepts - Progress 8

```{r}
# Step 1: Compute lm coefficients per Ofsted rating
lm_labels <- england_filtered_clean %>%
  group_by(OFSTEDRATING) %>%
  summarise(
    model = list(lm(P8MEA ~ PTFSM6CLA1A)),
    .groups = "drop"
  ) %>%
  mutate(
    intercept = sapply(model, function(m) coef(m)[1]),
    slope = sapply(model, function(m) coef(m)[2]),
    label = paste0("y = ", round(intercept, 2), " + ", round(slope, 2), "x")
  )

# Step 2: Merge label positions (optional: use median values for placement)
label_positions <- england_filtered_clean %>%
  group_by(OFSTEDRATING) %>%
  summarise(
    x = 0,
    y = 2,
    .groups = "drop"
  )

lm_labels <- left_join(lm_labels, label_positions, by = "OFSTEDRATING")

ggplot(england_filtered_clean, aes(y = P8MEA, x = PTFSM6CLA1A, colour = OFSTEDRATING)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_text(data = lm_labels, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) + 
  # Add linear model line for england_school_2022_23
  labs(title = "Progress 8 vs Overall Absence %, 2022-23",
       x = "% Overall Absence",
       y = "Attainment 8 Score",
       color = "Ofsted Rating") +
  theme_minimal() +
  facet_wrap(~ OFSTEDRATING)  # Facet plots for each Ofsted rating
  
```

## Different Slopes and Intercepts

-   Solution: can we just partition our data and run different models for different groups?
-   Answer: Well yes, you could, but it might also be useful to explore more systematically how slopes and intercepts vary between and within groups in your data - that is also useful information

In order to model these grouping factors more explicitly, we need a new type of model - a linear mixed effects model

## Jargon Alert!

-   Before we embark on our linear mixed effects journey, there are two key pieces of jargon you need to learn
-   ***Fixed Effects*** - A Fixed Effect is your traditional explanatory variable (or covariate) whose relationship with the outcome you are primarily interested in estimating for its own sake.
    -   Example: Proportion of disadvantaged students in a school. You want the single, best-estimated coefficient ($\beta$) for this factor.
-   ***Random Effects*** - A Random Effect is a grouping factor (or nesting factor) whose variability you want to account for, but whose specific individual levels you don't necessarily want to draw conclusions about.
    -   Example: The different Ofsted ratings (or individual Schools). You're interested in how much the relationship varies across these groups, not the specific effect of 'Longhill School'

## Fixed Effects - More Detail

-   Fixed effects estimate the mean relationship across all groups. They represent the "fixed" part of the model that applies to every observation.
    -   You estimate a single $\beta$ coefficient for a fixed effect, which represents the population average effect of that variable.
    -   Fixed effects can be either continuous (e.g., % of disadvantaged students in a school) or categorical (region, ofsted rating).
-   Depending on how you formulate your model, a fixed effect could be a random effect in a different context.

## Random Effects - More Detail

-   Random effects, (random intercepts and slopes) represent the deviations of each group's effect from the overall fixed-effect average.
    -   When you model a grouping factor (like Ofsted Rating) as a random effect, you are not estimating five separate coefficients (one for each rating).
    -   Instead, you estimate a variance term ($\sigma^2_{\text{group}}$) that quantifies how much the true group effects (intercepts and/or slopes) scatter around the overall mean effect.
    -   This approach is used when the groups (e.g., the 5 Ofsted categories or the hundreds of individual schools) are considered a random sample from a larger, unobserved population of groups.
    -   This allows the model to "borrow strength" across groups to stabilise estimates (the principle of shrinkage).

## Linear Mixed Effects Models

-   A Linear Mixed Effects (LME) model is a more general class of statistical model that features both a fixed-effects component (the population-average parameters) and a random-effects component (the group-specific deviations)
-   A common type of LME model is the multilevel or hierarchical linear model.
    -   Multilevel models focus specifically on nested data structures, e.g. students in classes $\rightarrow$ classes within schools $\rightarrow$ schools within local authorities $\rightarrow$ local authorities within regions
-   All multilevel models are linear mixed effects models, but linear mixed effects models can handle even more types of groupings (e.g. longitudinal - repeated observations over time)

## Linear Mixed Effects Models

![](L6_images/multilevel_data.webp) In practice, LME models essentially result in varying intercepts, slopes or both.

Multilevel Data Structures (Source:Â [Gelman & Hill (2006)](http://www.stat.columbia.edu/~gelman/arm/)) and <https://paulrjohnson.net/blog/2022-11-01-multilevel-model-r-cheatsheet/>

## Linear Mixed Effects Models

```{r}
#| message: false
#| warning: false
library(GGally)

ggpairs(england_filtered_clean, , mapping = aes(color = OFSTEDRATING), columns = c("P8MEA", "PTFSM6CLA1A", "PERCTOT", "OFSTEDRATING"))


```

## The Null Model

-   The first step in a linear mixed effects model is to fit what is often called a ***null model*** (otherwise know as the ***'Variance Components'*** / ***'Unconditional Means'*** Model)
-   Point of the null model is to partition the total variance in the outcome variable (Progress 8 - P8MEA) into the levels or components we think are relevant.
-   In our example, we have schools (Level 1 - our primary unit) and various grouping factors we could use e.g. local authority (level 2), region (level 3). Or we could use Ofsted rating as a level 2 factor.

## The Null Model - a 2 Level Model example

$$\mathbf{Y_{ij} = \gamma_{00} + u_{0j} + \epsilon_{ij}}$$

This equation shows that the total variability in $Y_{ij}$ (Progress 8) is decomposed into two sources:
-   Fixed Effect: $\mathbf{\gamma_{00}}$ (The overall population average - **grand/global mean**).
-   Random Effect (Level 1): $\mathbf{\epsilon_{ij}}$ (linked to the variation within groups/ratings, $\mathbf{\sigma^2_{\epsilon}}$).
-   Random Effect (Level 2): $\mathbf{u_{0j}}$ (linked to the variation between groups/ratings, $\mathbf{\sigma^2_{u_{0}}}$).

## Null Model - Level 1

-    $$\mathbf{Y_{ij} = \beta_{0j} + \epsilon_{ij}}$$$\mathbf{Y_{ij}}$: The outcome (e.g., Progress 8) for the $i^{th}$ school in the $j^{th}$ Ofsted rating.
-    $\mathbf{\beta_{0j}}$: The intercept for the specific Ofsted rating $j$. This represents the true mean Progress 8 for all schools within that rating. Because we haven't added any predictors yet, this is the only fixed part of the model.
-    $\mathbf{\epsilon_{ij}}$: The Level 1 residual error (or "school-level error"). This is the deviation of the $i^{th}$ school's P8MEA from its own rating group's mean ($\beta_{0j}$).
-    Assumption: $\epsilon_{ij} \sim N(0, \mathbf{\sigma^2_{\epsilon}})$ where $\mathbf{\sigma^2_{\epsilon}}$ is the Within-Group Variance (or Level 1 variance/Residual Variance).

## Null Model - Level 2

$$\mathbf{\beta_{0j} = \gamma_{00} + u_{0j}}$$$\mathbf{\beta_{0j}}$: The mean Progress 8 for the $j^{th}$ Ofsted rating (the intercept from Level 1).
$\mathbf{\gamma_{00}}$: The grand mean or the overall fixed intercept. This is the mean Progress 8 averaged across all Ofsted ratings. This is the fixed effect in the model.
$\mathbf{u_{0j}}$: The Level 2 residual error (or "group-level error"). This is the deviation of the $j^{th}$ Ofsted rating's mean ($\beta_{0j}$) from the grand mean ($\gamma_{00}$).
Assumption: $u_{0j} \sim N(0, \mathbf{\sigma^2_{u_{0}}})$ where $\mathbf{\sigma^2_{u_{0}}}$ is the Between-Group Variance (or Level 2 variance/Random Intercept Variance).



## The Null Model

1.  **Between-Group Variance** ($\sigma^2_{\text{OFSTED}}$ - or more generally $\mathbf{\sigma^2_{u_{0}}}$): The variability in average P8MEA that exists between the different Ofsted ratings.
2.  **Within-Group (Residual) Variance** ($\sigma^2_{\text{Residual}}$ - or more generally $\mathbf{\sigma^2_{\epsilon}}$): The variability in P8MEA that exists between schools within each rating (i.e., the school-level differences).

## The Null Model

```{r}
#| message: false
#| warning: false
#| align: center
#| out-width: 60%

# 1. Load the necessary library for plotting
library(ggplot2)

# --- Ensure OFSTEDRATING is an ordered factor for better plotting ---
# It appears you have six levels based on the OLS output, so we order them logically.
# Adjust the order if the true levels/baseline are different in your data.
rating_order <- c("Special Measures", "Serious Weaknesses", "Requires improvement", "Good", "Outstanding")
england_filtered_clean$OFSTEDRATING <- factor(
  england_filtered_clean$OFSTEDRATING,
  levels = rating_order,
  ordered = TRUE
)


## ## 1. Boxplot Visualization (Level 1 and Level 2 Variance) ## ##
boxplot_p8mea <- ggplot(england_filtered_clean, aes(x = OFSTEDRATING, y = P8MEA, fill = OFSTEDRATING)) +
  geom_boxplot(alpha = 0.7) +
  geom_hline(yintercept = mean(england_filtered_clean$P8MEA, na.rm = TRUE),
             linetype = "dashed", color = "black", linewidth = 1) +
  labs(
    title = "P8MEA Distribution Across Ofsted Ratings (The Null Model Structure)",
    subtitle = "Fixed Grand Mean (Dashed Line) and Random Intercepts (Box Medians)",
    x = "Ofsted Rating",
    y = "Progress 8 Score (P8MEA)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")

print(boxplot_p8mea)


```

-   All of the information in the NULL model is contained in this plot!
-   **Within-Group Variance** ($\mathbf{\sigma^2_{\epsilon}}$) - the height of each individual box and the length of its whiskers. Taller boxes and longer whiskers indicate more variability among schools within that single rating category.

## The Null Model

```{r}
#| message: false
#| warning: false
#| align: center
#| out-width: 60%

# 1. Load the necessary library for plotting
library(ggplot2)

# --- Ensure OFSTEDRATING is an ordered factor for better plotting ---
# It appears you have six levels based on the OLS output, so we order them logically.
# Adjust the order if the true levels/baseline are different in your data.
rating_order <- c("Special Measures", "Serious Weaknesses", "Requires improvement", "Good", "Outstanding")
england_filtered_clean$OFSTEDRATING <- factor(
  england_filtered_clean$OFSTEDRATING,
  levels = rating_order,
  ordered = TRUE
)


## ## 1. Boxplot Visualization (Level 1 and Level 2 Variance) ## ##
boxplot_p8mea <- ggplot(england_filtered_clean, aes(x = OFSTEDRATING, y = P8MEA, fill = OFSTEDRATING)) +
  geom_boxplot(alpha = 0.7) +
  geom_hline(yintercept = mean(england_filtered_clean$P8MEA, na.rm = TRUE),
             linetype = "dashed", color = "black", linewidth = 1) +
  labs(
    title = "P8MEA Distribution Across Ofsted Ratings (The Null Model Structure)",
    subtitle = "Fixed Grand Mean (Dashed Line) and Random Intercepts (Box Medians)",
    x = "Ofsted Rating",
    y = "Progress 8 Score (P8MEA)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")

print(boxplot_p8mea)


```

-   **Between-Group Variance** ($\mathbf{\sigma^2_{u_{0}}}$) - Differences between the mean/median lines of the boxplots for each rating category
-   The sum of these two variances ($\sigma^2_{\text{OFSTED}} + \sigma^2_{\text{Residual}}$) gives the **Total Variance** of P8MEA. This establishes the baseline level of clustering in the data before any other variables are considered

## The Null Model

```{r}
## ## 2. Density Plot Visualization (Comparing the Two Variance Components) ## ##
# This plot visually shows how much the groups overlap (small overlap means high ICC).
density_p8mea <- ggplot(england_filtered_clean, aes(x = P8MEA, fill = OFSTEDRATING, color = OFSTEDRATING)) +
  geom_density(alpha = 0.4) +
  labs(
    title = "Density of Progress 8 (P8MEA) by Ofsted Rating",
    subtitle = "Low overlap suggests large differences between ratings (High ICC)",
    x = "Progress 8 Score (P8MEA)",
    y = "Density"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(density_p8mea)
```

## The Null Model

$$\text{lmer}(\text{P8MEA} \sim 1 + (1|\text{OFSTEDRATING}), \text{data} = \dots)$$

## The Null Model

```{r}
library(lme4)

lm1 <- lm(P8MEA ~ PTFSM6CLA1A + OFSTEDRATING, data = england_filtered_clean)
summary(lm1)

lme1 <- lmer(P8MEA ~ 1 + (1|OFSTEDRATING), data = england_filtered_clean)
summary(lme1)

```

```{r}
lme2 <- lmer(P8MEA ~ PTFSM6CLA1A + (1|OFSTEDRATING), data = england_filtered_clean)
summary(lme2)
```
