import pandas as pd
import numpy as np
import janitor
from pathlib import Path
# Read CSV file
edubase_schools = pd.read_csv(
"https://www.dropbox.com/scl/fi/fhzafgt27v30lmmuo084y/edubasealldata20241003.csv?rlkey=uorw43s44hnw5k9js3z0ksuuq&raw=1",
encoding="cp1252",
low_memory=False,
dtype={"URN": str}
)
edubase_schools = edubase_schools.clean_names()
#py_edubase_schools.dtypes
#dtype_df = py_edubase_schools.dtypes.reset_index()
#dtype_df.columns = ["column_name", "dtype"]
########################################
# Define base path and common NA values - NOTE YOU WILL NEED TO DOWNLOAD THIS DATA AND PUT INTO YOUR OWN base_path LOCATION ON YOUR MACHINE - not this one as this is my path!!!
base_path = Path("E:/QM/sessions/L6_data/Performancetables_130242/2022-2023")
##################################################
na_values_common = ["", "NA", "SUPP", "NP", "NE"]
na_values_extended = na_values_common + ["SP", "SN"]
na_values_attainment = na_values_extended + ["LOWCOV", "NEW"]
na_values_mats = na_values_common + ["SUPPMAT"]
na_all = ["", "NA", "SUPP", "NP", "NE", "SP", "SN", "LOWCOV", "NEW", "SUPPMAT", "NaN"]
# Absence data
england_abs = pd.read_csv(base_path / "england_abs.csv", na_values=na_all, dtype={"URN": str})
# Census data
england_census = pd.read_csv(base_path / "england_census.csv", na_values=na_all, dtype={"URN": str})
england_census.iloc[:, 4:23] = england_census.iloc[:, 4:23].apply(lambda col: pd.to_numeric(col.astype(str).str.replace('%', '', regex=False), errors="coerce"))
# KS4 MATs performance data
england_ks4_mats_performance = pd.read_csv(base_path / "england_ks4-mats-performance.csv", na_values=na_all, encoding="cp1252", low_memory=False, dtype={"URN": str})
england_ks4_mats_performance["TRUST_UID"] = england_ks4_mats_performance["TRUST_UID"].astype(str)
england_ks4_mats_performance["P8_BANDING"] = england_ks4_mats_performance["P8_BANDING"].astype(str)
england_ks4_mats_performance["INSTITUTIONS_INMAT"] = england_ks4_mats_performance["INSTITUTIONS_INMAT"].astype(str)
cols_to_convert = england_ks4_mats_performance.columns[10:]
exclude = ["P8_BANDING", "INSTITUTIONS_INMAT"]
cols_to_convert = [col for col in cols_to_convert if col not in exclude]
england_ks4_mats_performance[cols_to_convert] = england_ks4_mats_performance[cols_to_convert].apply(lambda col: pd.to_numeric(col.astype(str).str.replace('%', '', regex=False), errors="coerce"))
# KS4 pupil destination data
england_ks4_pupdest = pd.read_csv(base_path / "england_ks4-pupdest.csv", na_values=na_all, dtype={"URN": str})
england_ks4_pupdest.iloc[:, 7:82] = england_ks4_pupdest.iloc[:, 7:82].apply(lambda col: pd.to_numeric(col.astype(str).str.replace('%', '', regex=False), errors="coerce"))
# KS4 final attainment data
england_ks4final = pd.read_csv(base_path / "england_ks4final.csv", na_values=na_all, dtype={"URN": str})
start_col = "TOTPUPS"
end_col = "PTOTENT_E_COVID_IMPACTED_PTQ_EE"
cols_range = england_ks4final.loc[:, start_col:end_col].columns
# Strip % signs and convert to numeric
england_ks4final[cols_range] = england_ks4final[cols_range].apply(
lambda col: pd.to_numeric(col.astype(str).str.replace('%', '', regex=False), errors="coerce")
)
# School information data
england_school_information = pd.read_csv(
base_path / "england_school_information.csv",
na_values=na_all,
dtype={"URN": str},
parse_dates=["OFSTEDLASTINSP"],
dayfirst=True  # Adjust if needed
)
# Left join england_ks4final with england_abs, census, and school information
england_school_2022_23 = (
england_ks4final
.merge(england_abs, on="URN", how="left")
.merge(england_census, on="URN", how="left")
.merge(england_school_information, on="URN", how="left")
.merge(edubase_schools, left_on="URN", right_on="urn", how="left")
)
#| echo: true
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
# Compute statistics
median_value = england_school_2022_23["ATT8SCR"].median(skipna=True)
mean_value = england_school_2022_23["ATT8SCR"].mean(skipna=True)
sd_value = england_school_2022_23["ATT8SCR"].std(skipna=True)
# Set up the figure
plt.figure(figsize=(10, 6))
# Histogram with density
sns.histplot(
data=england_school_2022_23,
x="ATT8SCR",
stat="density",
binwidth=1,
color="#4E3C56",
alpha=0.4,
linewidth=0.5,
edgecolor="white"
)
# Overlay normal distribution curve
x_vals = np.linspace(
england_school_2022_23["ATT8SCR"].min(),
england_school_2022_23["ATT8SCR"].max(),
500
)
normal_density = (
1 / (sd_value * np.sqrt(2 * np.pi))
) * np.exp(-0.5 * ((x_vals - mean_value) / sd_value) ** 2)
plt.plot(x_vals, normal_density, color="#2E6260", linewidth=1)
# Add vertical lines for median and mean
plt.axvline(median_value, color="black", linestyle="dotted", linewidth=1)
plt.axvline(mean_value, color="#F9DD73", linestyle="solid", linewidth=1)
# Annotate median and mean
plt.text(median_value, plt.gca().get_ylim()[1]*0.95, f"Median = {median_value:.1f}",
color="black", ha="center", va="top", fontsize=10)
plt.text(mean_value, plt.gca().get_ylim()[1]*0.85, f"Mean = {mean_value:.1f}",
color="#F9DD73", ha="center", va="top", fontsize=10)
# Customize labels and theme
plt.title("Attainment 8 - All Schools England and Wales, 2022/23 Academic Year")
plt.xlabel("Attainment 8 Score")
plt.ylabel("Density")
sns.despine()
plt.tight_layout()
# Show the plot
# plt.show()
import matplotlib.pyplot as plt
import seaborn as sns
# Set up the figure
plt.figure(figsize=(12, 6))
# Boxplot grouped by MINORGROUP
sns.boxplot(
x='ATT8SCR',
data=england_school_2022_23,
color="#EDD971",
fliersize=0,
linewidth=1
)
# Jittered points
sns.stripplot(
x='ATT8SCR',
data=england_school_2022_23,
hue='MINORGROUP',
dodge=False,
jitter=True,
alpha=0.5,
size=4,
palette='turbo'
)
# Customize the plot
plt.title("Attainment 8 - All Schools 2022/23 Academic Year")
plt.xlabel("Attainment 8 Score")
plt.ylabel("")
plt.legend(title="School Type", loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=2)
sns.despine()
plt.tight_layout()
# Show the plot
plt.show()
import pandas as pd
## check all of your variable names first as R and python will call them something different
column_df = pd.DataFrame({'Column Names': england_school_2022_23.columns.tolist()})
# Define excluded MINORGROUP values
excluded_groups = ["Special school", "Independent school", "College", None]
# Filter and select columns
england_filtered = (
england_school_2022_23[
~england_school_2022_23["MINORGROUP"].isin(excluded_groups) &
(england_school_2022_23["phaseofeducation_name_"] == "Secondary") &
(england_school_2022_23["establishmentstatus_name_"] == "Open")
][["URN", "SCHNAME_x", "LEA", "TOWN_x", "TOTPUPS", "ATT8SCR", "OFSTEDRATING", "MINORGROUP", "PTFSM6CLA1A"]]
)
#| include: false
import pandas as pd
## check all of your variable names first as R and python will call them something different
column_df = pd.DataFrame({'Column Names': england_school_2022_23.columns.tolist()})
# Define excluded MINORGROUP values
excluded_groups = ["Special school", "Independent school", "College", None]
# Filter and select columns
england_filtered = (
england_school_2022_23[
~england_school_2022_23["MINORGROUP"].isin(excluded_groups) &
(england_school_2022_23["phaseofeducation_name_"] == "Secondary") &
(england_school_2022_23["establishmentstatus_name_"] == "Open")
][["URN", "SCHNAME_x", "LEA", "LANAME", "TOWN_x", "gor_name_", "TOTPUPS", "ATT8SCR", "ATT8SCRENG", "ATT8SCRMAT", "ATT8SCR_FSM6CLA1A", "ATT8SCR_NFSM6CLA1A", "ATT8SCR_BOYS", "ATT8SCR_GIRLS", "P8MEA", "P8MEA_FSM6CLA1A", "P8MEA_NFSM6CLA1A", "PTFSM6CLA1A", "PTNOTFSM6CLA1A", "PNUMEAL", "PNUMENGFL", "PTPRIORLO", "PTPRIORHI", "NORB", "NORG", "PNUMFSMEVER", "PERCTOT", "PPERSABS10", "SCHOOLTYPE_x", "RELCHAR", "ADMPOL_y", "gender_name_", "OFSTEDRATING", "MINORGROUP", "easting", "northing"]]
)
#| include: false
camden_sub = england_filtered[england_filtered['LANAME'] == 'Camden']
leeds_sub = england_filtered[england_filtered['LANAME'] == 'Leeds']
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# Combine the datasets
combined_data = pd.concat([camden_sub, leeds_sub])
# Create a function to make and customize the plot
def make_plot():
g = sns.FacetGrid(combined_data, col="LANAME", height=5, aspect=1)
g.map_dataframe(
sns.scatterplot,
x="PTFSM6CLA1A",
y="ATT8SCR",
color="steelblue",
alpha=0.7,
s=60
)
g.set_axis_labels("% KS4 Pupils Disadvantaged (PTFSM6CLA1A)", "Attainment 8 Score (ATT8SCR)")
g.fig.suptitle("Attainment 8 vs % Disadvantaged by Local Authority", fontsize=16)
g.fig.tight_layout()
g.fig.subplots_adjust(top=0.85)
plt.show()
# Call the function once
make_plot()
#| include: false
import geopandas as gpd
import folium
from branca.colormap import linear
# Create GeoDataFrame from BNG coordinates
sf_df_bng = gpd.GeoDataFrame(
camden_sub,
geometry=gpd.points_from_xy(camden_sub['easting'], camden_sub['northing']),
crs='EPSG:27700'
)
# Reproject to WGS84
sf_df = sf_df_bng.to_crs('EPSG:4326')
# Extract lat/lon from geometry
sf_df['lat'] = sf_df.geometry.y
sf_df['lon'] = sf_df.geometry.x
# Scale marker size by TOTPUPS
min_pupils = sf_df['TOTPUPS'].min()
max_pupils = sf_df['TOTPUPS'].max()
sf_df['size_scale'] = 4 + (sf_df['TOTPUPS'] - min_pupils) * (12 - 4) / (max_pupils - min_pupils)
# Create magma color scale based on ATT8SCR
att_values = sf_df['ATT8SCR'].dropna()
vmin, vmax = sorted([att_values.min(), att_values.max()])
magma_scale = linear.magma.scale(vmin, vmax)
magma_scale.caption = 'ATT8SCR'
# Create interactive map centered on Camden
center_lat = sf_df['lat'].mean()
center_lon = sf_df['lon'].mean()
m = folium.Map(location=[center_lat, center_lon], tiles='CartoDB.Positron', zoom_start=12)
# Add circle markers
for _, row in sf_df.iterrows():
popup_html = f"<strong>{row['SCHNAME_x']}</strong><br>Pupils: {row['TOTPUPS']}"
folium.CircleMarker(
location=[row['lat'], row['lon']],
radius=row['size_scale'],
color=magma_scale(row['ATT8SCR']),
fill=True,
fill_color=magma_scale(row['ATT8SCR']),
fill_opacity=0.8,
popup=folium.Popup(popup_html, max_width=250)
).add_to(m)
# Add color legend
magma_scale.add_to(m)
# Save map
m.save("interactive_school_map.html")
import geopandas as gpd
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib.colors import Normalize
import contextily as ctx
# Reproject to Web Mercator for contextily
sf_df_mercator = sf_df_bng.to_crs(epsg=3857)
# Scale marker size
min_val = sf_df_mercator['TOTPUPS'].min()
max_val = sf_df_mercator['TOTPUPS'].max()
sf_df_mercator['size_scale'] = 4 + (sf_df_mercator['TOTPUPS'] - min_val) * (12 - 4) / (max_val - min_val)
# Color mapping
norm = Normalize(vmin=sf_df_mercator['ATT8SCR'].min(), vmax=sf_df_mercator['ATT8SCR'].max())
cmap = plt.colormaps['magma']
sf_df_mercator['color'] = sf_df_mercator['ATT8SCR'].apply(lambda x: cmap(norm(x)))
# Plot
fig, ax = plt.subplots(figsize=(10, 10))
sf_df_mercator.plot(ax=ax, color=sf_df_mercator['color'], markersize=sf_df_mercator['size_scale']**2, alpha=0.8)
# Add basemap
ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)
# Final touches
ax.set_title("Static Map of Schools Colored by ATT8SCR and Sized by TOTPUPS", fontsize=14)
ax.set_axis_off()
# Colorbar
sm = cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.03, pad=0.01)
cbar.set_label('ATT8SCR', fontsize=12)
plt.tight_layout()
plt.savefig("static_school_map_with_basemap.png", dpi=300)
plt.show()
#| echo: true
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
# Load your data into a DataFrame named england_filtered
# england_filtered = pd.read_csv("your_data.csv")
# Apply log10 transformation (replace 0s to avoid log(0))
england_filtered['log_PTFSM6CLA1A'] = np.log10(england_filtered['PTFSM6CLA1A'].replace(0, np.nan))
england_filtered['log_ATT8SCR'] = np.log10(england_filtered['ATT8SCR'].replace(0, np.nan))
# Drop rows with NaNs from log(0)
england_filtered = england_filtered.dropna(subset=['log_PTFSM6CLA1A', 'log_ATT8SCR'])
# Set theme
sns.set_theme(style="darkgrid")
# Create jointplot
g = sns.jointplot(
x="log_PTFSM6CLA1A",
y="log_ATT8SCR",
data=england_filtered,
kind="reg",
truncate=False,
color="m",
height=7
)
# Label axes
g.set_axis_labels("log10(PTFSM6CLA1A)", "log10(ATT8SCR)")
plt.show()
#| echo: true
import seaborn as sns
import matplotlib.pyplot as plt
# Set the theme
sns.set_theme(style="darkgrid")
# Create side-by-side histograms
fig, axes = plt.subplots(1, 2, figsize=(14, 6))
# Histogram for PTFSM6CLA1A
sns.histplot(data=england_filtered, x="PTFSM6CLA1A", ax=axes[0], kde=True, color="skyblue")
axes[0].set_title("Histogram of PTFSM6CLA1A")
axes[0].set_xlabel("PTFSM6CLA1A")
axes[0].set_ylabel("Frequency")
# Histogram for ATT8SCR
sns.histplot(data=england_filtered, x="ATT8SCR", ax=axes[1], kde=True, color="salmon")
axes[1].set_title("Histogram of ATT8SCR")
axes[1].set_xlabel("ATT8SCR")
axes[1].set_ylabel("Frequency")
plt.tight_layout()
plt.show()
import numpy as np
import statsmodels.api as sm
# Log-transform the variables
camden_sub['log_ATT8SCR'] = np.log(camden_sub['ATT8SCR'])
camden_sub['log_PTFSM6CLA1A'] = np.log(camden_sub['PTFSM6CLA1A'])
# Define independent and dependent variables
X = sm.add_constant(camden_sub['log_PTFSM6CLA1A'])  # adds intercept
y = camden_sub['log_ATT8SCR']
# Fit the model
camden_model1 = sm.OLS(y, X).fit()
#camden_summary = extract_model_summary(camden_model1, 'Camden Model')
# Print summary
print(camden_model1.summary())
import numpy as np
import statsmodels.api as sm
# Log-transform safely: replace non-positive values with NaN
leeds_sub['log_ATT8SCR'] = np.where(leeds_sub['ATT8SCR'] > 0, np.log(leeds_sub['ATT8SCR']), np.nan)
leeds_sub['log_PTFSM6CLA1A'] = np.where(leeds_sub['PTFSM6CLA1A'] > 0, np.log(leeds_sub['PTFSM6CLA1A']), np.nan)
# Drop rows with NaNs in either column
leeds_clean = leeds_sub.dropna(subset=['log_ATT8SCR', 'log_PTFSM6CLA1A'])
# Define independent and dependent variables
X = sm.add_constant(leeds_clean['log_PTFSM6CLA1A'])  # adds intercept
y = leeds_clean['log_ATT8SCR']
# Fit the model
leeds_model1 = sm.OLS(y, X).fit()
#leeds_summary = extract_model_summary(leeds_model1, 'Leeds Model')
# Print summary
print(leeds_model1.summary())
import pandas as pd
results_table = summary_col(
results=[camden_model1, leeds_model1, england_model1],
model_names=['Camden Model', 'Leeds Model', 'England Model'],
stars=True,
float_format="%0.3f",
# You can customize what model statistics show up here (like R2, N, F-stat)
info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
'R-squared':lambda x: "{:.3f}".format(x.rsquared),
'Adj. R-squared':lambda x: "{:.3f}".format(x.rsquared_adj)}
)
#
# # Round for readability
print(results_table)
import numpy as np
import statsmodels.api as sm
# Log-transform safely: replace non-positive values with NaN
england_filtered['log_ATT8SCR'] = np.where(england_filtered['ATT8SCR'] > 0, np.log(england_filtered['ATT8SCR']), np.nan)
england_filtered['log_PTFSM6CLA1A'] = np.where(england_filtered['PTFSM6CLA1A'] > 0, np.log(england_filtered['PTFSM6CLA1A']), np.nan)
# Drop rows with NaNs in either column
england_clean = england_filtered.dropna(subset=['log_ATT8SCR', 'log_PTFSM6CLA1A'])
# Define independent and dependent variables
X = sm.add_constant(england_clean['log_PTFSM6CLA1A'])  # adds intercept
y = england_clean['log_ATT8SCR']
# Fit the model
england_model1 = sm.OLS(y, X).fit()
#england_summary = extract_model_summary(england_model1, 'England Model')
# Print summary
print(england_model1.summary())
import pandas as pd
results_table = summary_col(
results=[camden_model1, leeds_model1, england_model1],
model_names=['Camden Model', 'Leeds Model', 'England Model'],
stars=True,
float_format="%0.3f",
# You can customize what model statistics show up here (like R2, N, F-stat)
info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
'R-squared':lambda x: "{:.3f}".format(x.rsquared),
'Adj. R-squared':lambda x: "{:.3f}".format(x.rsquared_adj)}
)
#
# # Round for readability
print(results_table)
results_table = summary_col(
results=[camden_model1, leeds_model1, england_model1],
model_names=['Camden Model', 'Leeds Model', 'England Model'],
stars=True,
float_format="%0.3f",
# You can customize what model statistics show up here (like R2, N, F-stat)
info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
'R-squared':lambda x: "{:.3f}".format(x.rsquared),
'Adj. R-squared':lambda x: "{:.3f}".format(x.rsquared_adj)}
)
import pandas as pd
import statsmodels.api as sm
results_table = summary_col(
results=[camden_model1, leeds_model1, england_model1],
model_names=['Camden Model', 'Leeds Model', 'England Model'],
stars=True,
float_format="%0.3f",
# You can customize what model statistics show up here (like R2, N, F-stat)
info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
'R-squared':lambda x: "{:.3f}".format(x.rsquared),
'Adj. R-squared':lambda x: "{:.3f}".format(x.rsquared_adj)}
)
from statsmodels.iolib.summary2 import summary_col
results_table = summary_col(
results=[camden_model1, leeds_model1, england_model1],
model_names=['Camden Model', 'Leeds Model', 'England Model'],
stars=True,
float_format="%0.3f",
# You can customize what model statistics show up here (like R2, N, F-stat)
info_dict={'N':lambda x: "{0:d}".format(int(x.nobs)),
'R-squared':lambda x: "{:.3f}".format(x.rsquared),
'Adj. R-squared':lambda x: "{:.3f}".format(x.rsquared_adj)}
)
print(results_table)
